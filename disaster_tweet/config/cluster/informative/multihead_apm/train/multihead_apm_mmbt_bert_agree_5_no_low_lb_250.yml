algorithm: multihead_apm_mmbt_bert

# optimization configs
epoch: 20
num_train_iter: 1000000 
num_eval_iter: 1000000
num_log_iter: 50    
optim: AdamW
lr: 0.00001
layer_decay: 0.5
batch_size: 8
eval_batch_size: 8

# dataset configs
dataset: disaster
task: informative
num_labels: 500
crop_ratio: 0.875
img_size: 224
train_filename: train_eda.jsonl
dev_filename: dev_eda.jsonl
test_filename: test_eda.jsonl
unlabeled_filename: unlabeled_eda.jsonl
data_dir: /export/home/acs/stud/r/robert.popovici/licenta/datasets/informative
img_dir: /export/home/acs/stud/r/robert.popovici/licenta/datasets
weak_text_tag: eda_01 
strong_text_tag: eda_02 

# algorithm specific configs
hard_label: True
uratio: 3
ulb_loss_ratio: 1.0
use_agreement_apm: True
apm_percentile: 0.05
# use_debug: True

# device configs
gpu: 0
world_size: 1
num_workers: 2
distributed: False

# test configs
save_dir: ./saved_models/informative/multihead_apm/train
save_name: multihead-apm-mmbt-bert-agree-5-no-low-lb-250
overwrite: False
